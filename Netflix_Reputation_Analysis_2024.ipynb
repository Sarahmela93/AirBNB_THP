{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sarahmela93/AirBNB_THP/blob/main/Netflix_Reputation_Analysis_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyCkpIvb9pwV"
      },
      "source": [
        "# Netflix Reputation Analysis 2024\n",
        "## Web Scraping & Sentiment Classification\n",
        "\n",
        "### Project Team:\n",
        "- SOUISSI Youssef\n",
        "- MELAIKIA Sarah\n",
        "- Derradji Mourad\n",
        "- BOUCHAREB Moncef Amine\n",
        "\n",
        "### Last Update: [25/11/2024] Moncef"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scrapping Twitter et Google news Format CSV"
      ],
      "metadata": {
        "id": "nWfHvIJxGNr5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pC6wDidY9pwY",
        "outputId": "dd14e7a6-f6b3-47f3-dba8-1acbaf938a20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Limite de requêtes atteinte (Tentative 1)\n",
            "Limite de requêtes atteinte (Tentative 2)\n",
            "Limite de requêtes atteinte (Tentative 3)\n"
          ]
        }
      ],
      "source": [
        "import tweepy\n",
        "from textblob import TextBlob\n",
        "import pandas as pd\n",
        "import re\n",
        "import unicodedata\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "# Configuration de l'authentification Twitter\n",
        "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAANetxAEAAAAAT7tuge58Eod19VVvnxCKjXtVvno%3D5e8CCYViSaF3IcSDSC36jpafOMbQ0ZVKVqqGSHcxIkzRkL1tY5\"\n",
        "\n",
        "# Configuration de l'authentification\n",
        "def configurer_client():\n",
        "    \"\"\"\n",
        "    Configurer le client Twitter avec gestion des erreurs\n",
        "    \"\"\"\n",
        "    try:\n",
        "        client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
        "        return client\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur de configuration du client : {e}\")\n",
        "        return None\n",
        "\n",
        "def nettoyer_texte(texte):\n",
        "    \"\"\"\n",
        "    Nettoie et formate le texte\n",
        "    \"\"\"\n",
        "    # Convertir en chaîne si ce n'est pas déjà le cas\n",
        "    texte = str(texte)\n",
        "\n",
        "    # Supprimer les liens\n",
        "    texte = re.sub(r'http\\S+', '', texte)\n",
        "\n",
        "    # Normaliser les caractères Unicode\n",
        "    texte = unicodedata.normalize('NFKD', texte)\n",
        "\n",
        "    # Supprimer les caractères non-imprimables et contrôles\n",
        "    texte = ''.join(char for char in texte if unicodedata.category(char)[0] not in ['C', 'Z'])\n",
        "\n",
        "    # Nettoyer les espaces multiples\n",
        "    texte = re.sub(r'\\s+', ' ', texte).strip()\n",
        "\n",
        "    return texte\n",
        "\n",
        "def analyser_sentiment(texte):\n",
        "    \"\"\"\n",
        "    Analyse le sentiment d'un texte\n",
        "    \"\"\"\n",
        "    sentiment_analysis = TextBlob(texte)\n",
        "    sentiment_score = sentiment_analysis.sentiment.polarity\n",
        "\n",
        "    if sentiment_score > 0.5:\n",
        "        return \"Très Positif\"\n",
        "    elif 0 < sentiment_score <= 0.5:\n",
        "        return \"Positif\"\n",
        "    elif sentiment_score == 0:\n",
        "        return \"Neutre\"\n",
        "    elif -0.5 < sentiment_score < 0:\n",
        "        return \"Négatif\"\n",
        "    else:\n",
        "        return \"Très Négatif\"\n",
        "\n",
        "def extraire_hashtags(texte):\n",
        "    \"\"\"\n",
        "    Extrait les hashtags du texte\n",
        "    \"\"\"\n",
        "    return ' '.join(re.findall(r\"#(\\w+)\", texte))\n",
        "\n",
        "def recuperer_tweets(client, query, max_tentatives=3):\n",
        "    \"\"\"\n",
        "    Récupérer les tweets avec gestion des erreurs et des limites de requêtes\n",
        "    \"\"\"\n",
        "    for tentative in range(max_tentatives):\n",
        "        try:\n",
        "            # Recherche des tweets récents avec gestion des erreurs\n",
        "            tweets = client.search_recent_tweets(\n",
        "                query=query,\n",
        "                max_results=20,\n",
        "                tweet_fields=[\"author_id\", \"created_at\", \"text\", \"public_metrics\", \"id\"],\n",
        "                expansions=[\"author_id\"]\n",
        "            )\n",
        "\n",
        "            # Vérifier si des tweets ont été trouvés\n",
        "            if tweets.data:\n",
        "                return tweets\n",
        "\n",
        "            print(f\"Aucun tweet trouvé (Tentative {tentative + 1})\")\n",
        "            time.sleep(2 ** tentative)  # Backoff exponentiel\n",
        "\n",
        "        except tweepy.TooManyRequests:\n",
        "            print(f\"Limite de requêtes atteinte (Tentative {tentative + 1})\")\n",
        "            time.sleep(15 * 60)  # Attendre 15 minutes\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erreur lors de la récupération : {e}\")\n",
        "            time.sleep(2 ** tentative)\n",
        "\n",
        "    return None\n",
        "\n",
        "def collecter_donnees_twitter(query):\n",
        "    \"\"\"\n",
        "    Collecter et traiter les données Twitter\n",
        "    \"\"\"\n",
        "    # Configurer le client\n",
        "    client = configurer_client()\n",
        "    if not client:\n",
        "        return []\n",
        "\n",
        "    # Récupérer les tweets\n",
        "    tweets_response = recuperer_tweets(client, query)\n",
        "\n",
        "    # Liste pour stocker les résultats\n",
        "    results = []\n",
        "\n",
        "    if tweets_response and tweets_response.data:\n",
        "        # Créer un dictionnaire des auteurs\n",
        "        users = {user.id: user.username for user in tweets_response.includes['users']} if tweets_response.includes else {}\n",
        "\n",
        "        # Traitement des tweets\n",
        "        for tweet in tweets_response.data:\n",
        "            # Texte nettoyé\n",
        "            texte_nettoye = nettoyer_texte(tweet.text)\n",
        "\n",
        "            # Construction du lien du tweet\n",
        "            tweet_link = f\"https://twitter.com/{users.get(tweet.author_id, 'user')}/status/{tweet.id}\"\n",
        "\n",
        "            # Ajout des informations dans la liste des résultats\n",
        "            results.append({\n",
        "                \"ID Tweet\": tweet.id,\n",
        "                \"Auteur\": users.get(tweet.author_id, \"Inconnu\"),\n",
        "                \"Date\": tweet.created_at.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                \"Texte Original\": tweet.text,\n",
        "                \"Texte Nettoyé\": texte_nettoye,\n",
        "                \"Hashtags\": extraire_hashtags(tweet.text),\n",
        "                \"Nombre de Likes\": tweet.public_metrics.get(\"like_count\", 0),\n",
        "                \"Nombre de Retweets\": tweet.public_metrics.get(\"retweet_count\", 0),\n",
        "                \"Sentiment\": analyser_sentiment(tweet.text),\n",
        "                \"Score de Sentiment\": round(TextBlob(tweet.text).sentiment.polarity, 3),\n",
        "                \"Lien du Tweet\": tweet_link\n",
        "            })\n",
        "\n",
        "    return results\n",
        "\n",
        "def main():\n",
        "    # Requête de recherche\n",
        "    query = \"@Netflix Arcane -is:retweet lang:en\"\n",
        "\n",
        "    # Collecter les données\n",
        "    tweet_data = collecter_donnees_twitter(query)\n",
        "\n",
        "    # Vérifier si des données ont été collectées\n",
        "    if tweet_data:\n",
        "        # Créer le DataFrame\n",
        "        df = pd.DataFrame(tweet_data)\n",
        "\n",
        "        # Réorganisation des colonnes\n",
        "        colonnes_ordre = [\n",
        "            \"ID Tweet\", \"Auteur\", \"Date\",\n",
        "            \"Texte Original\", \"Texte Nettoyé\", \"Hashtags\",\n",
        "            \"Nombre de Likes\", \"Nombre de Retweets\",\n",
        "            \"Sentiment\", \"Score de Sentiment\", \"Lien du Tweet\"\n",
        "        ]\n",
        "\n",
        "        # Sélectionner et ordonner les colonnes\n",
        "        df = df[colonnes_ordre]\n",
        "\n",
        "        # Affichage console\n",
        "        print(\"\\n--- Analyse des Tweets ---\")\n",
        "        print(df.to_string(index=False))\n",
        "\n",
        "        # Statistiques de sentiment\n",
        "        print(\"\\n--- Répartition des Sentiments ---\")\n",
        "        print(df[\"Sentiment\"].value_counts())\n",
        "\n",
        "        # Nom de fichier avec date\n",
        "        date_fichier = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "        # Chemins de fichiers\n",
        "        fichier_excel = f'tweets_netflix_arcane_{date_fichier}.xlsx'\n",
        "        fichier_csv = f'tweets_netflix_arcane_{date_fichier}.csv'\n",
        "\n",
        "        try:\n",
        "            # Export Excel\n",
        "            df.to_excel(fichier_excel, index=False, engine='openpyxl')\n",
        "\n",
        "            # Export CSV\n",
        "            df.to_csv(fichier_csv, index=False)\n",
        "\n",
        "            print(\"\\n--- Export réussi ---\")\n",
        "            print(f\"Fichiers créés :\")\n",
        "            print(f\"1. {fichier_excel}\")\n",
        "            print(f\"2. {fichier_csv}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erreur lors de l'export : {e}\")\n",
        "\n",
        "    else:\n",
        "        print(\"Aucune donnée n'a pu être récupérée.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nojLG_JTC8xe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}